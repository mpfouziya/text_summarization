{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFhZhQtQgC-w"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Entity\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class ModelTrainerConfig:\n",
        "  root_dir: Path\n",
        "  data_path:Path\n",
        "  model_ckpt: Path\n",
        "  num_train_epochs: int\n",
        "  warmup_steps: int\n",
        "  per_device_train_batch_size: int\n",
        "  weight_decay: float\n",
        "  logging_steps: int\n",
        "  evaluation_strategy: str\n",
        "  eval_steps: int\n",
        "  save_steps: float\n",
        "  gradient_accumulation_steps: int"
      ],
      "metadata": {
        "id": "5XjYUb8H5YaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configration Manager\n",
        "from src.text_summarization.utils.common import read_yaml, create_directories\n",
        "\n",
        "\n",
        "class ConfigurationManager:\n",
        "    def __init__(\n",
        "            self,\n",
        "            config_filepath=CONFIG_FILE_PATH,\n",
        "            params_filepath=PARAMS_FILE_PATH):\n",
        "        self.config = read_yaml(config_filepath)\n",
        "        self.params = read_yaml(params_filepath)\n",
        "\n",
        "        create_directories([self.config.artifacts_root])\n",
        "\n",
        "    def get_model_trainer_config(self)->ModelTrainerConfig:\n",
        "       config = self.config.model_trainer\n",
        "       params = self.params.TrainingArguments\n",
        "\n",
        "       model_trainer_config = ModelTrainerConfig(\n",
        "        root_dir = config.root_dir,\n",
        "        data_path  =config.data_path,\n",
        "        model_ckpt = config.model_ckpt,\n",
        "        num_train_epochs = params.num_train_epochs,\n",
        "        warmup_steps = params.warmup_steps,\n",
        "        per_device_train_batch_size = params.per_device_train_batch_size,\n",
        "        weight_decay = params.weight_decay,\n",
        "        logging_steps = params.logging_steps,\n",
        "        evaluation_strategy = params.evaluation_strategy,\n",
        "        eval_steps = params.eval_steps,\n",
        "        save_steps = params.save_steps,\n",
        "        gradient_accumulation_steps = params.gradient_accumulation_steps\n",
        "      )\n",
        "       return model_trainer_config"
      ],
      "metadata": {
        "id": "bD1PYWwE59Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Components\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from datasets import load_dataset, load_from_disk\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "HPuZ5Thu7wby"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate\n",
        "!pip uninstall -y transformers accelerate\n",
        "!pip install transformers accelerate"
      ],
      "metadata": {
        "id": "fDNqapRRAmJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTrainer:\n",
        "  def __init__(self, config:ModelTrainerConfig):\n",
        "    self.config = config\n",
        "\n",
        "  def train(self):\n",
        "    device =\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    tokenizer=AutoTokenizer.from_pretrained(self.config.model_ckpt)\n",
        "    model_pegasus=AutoModelForSeq2SeqLM.from_pretrained(self.config.model_ckpt).to(device)\n",
        "    seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model = model_pegasus)\n",
        "\n",
        "    dataset_samsum_pt = load_from_disk(self.config.data_path)\n",
        "\n",
        "    trainer_args = TrainingArguments(\n",
        "        output_dir=self.config.root_dir, num_train_epochs=self.config.num_train_epochs, warmup_steps = self.config.warmup_steps,\n",
        "        per_device_train_batch_size = self.config.per_device_train_batch_size,\n",
        "        weight_decay = self.config.weight_decay,\n",
        "        logging_steps = self.config.logging_steps,\n",
        "        evaluation_strategy = self.config.evaluation_strategy,\n",
        "        eval_steps = self.config.eval_steps,\n",
        "        save_steps = self.config.save_steps,\n",
        "        gradient_accumulation_steps = self.config.gradient_accumulation_steps\n",
        "    )\n",
        "    trainer = Trainer(model=model_pegasus, args=trainer_args,\n",
        "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
        "                  train_dataset=dataset_samsum_pt[\"test\"],\n",
        "                  eval_dataset=dataset_samsum_pt[\"validation\"])\n",
        "    trainer.train()\n",
        "    model_pegasus.save_pretrained(os.path.join(self.config.root_dir, \"pegasus-samsum-model\"))\n",
        "    tokenizer.save_pretrained(os.path.join(self.config.root_dir,\"tokenizer\"))"
      ],
      "metadata": {
        "id": "FYnIOiHu9AuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline\n",
        "try:\n",
        "  config=ConfigurationManager()\n",
        "  model_trainer_config = config.get_model_trainer_config()\n",
        "  model_trainer_config = ModelTrainer(config=model_trainer_config)\n",
        "  model_trainer_config.train()\n",
        "\n",
        "except Exception as e:\n",
        "  raise e\n"
      ],
      "metadata": {
        "id": "s5fZ5ox7_t5v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}